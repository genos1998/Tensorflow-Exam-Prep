{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93be1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers,Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pathlib\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f894908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateReducerCb(tf.keras.callbacks.Callback):\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    old_lr = self.model.optimizer.lr.read_value()\n",
    "    new_lr = old_lr * 0.99\n",
    "    print(\"\\nEpoch: {}. Reducing Learning Rate from {} to {}\".format(epoch, old_lr, new_lr))\n",
    "    self.model.optimizer.lr.assign(new_lr)\n",
    "    \n",
    "def create_checkpoint_callback(model_name):\n",
    "  return tf.keras.callbacks.ModelCheckpoint(filepath=f\"{model_name}/checkpoint.ckpt\",\n",
    "                                                          #  monitor=\"val_accuracy\",\n",
    "                                                           save_best_only=True,\n",
    "                                                           save_weights_only=True,\n",
    "                                                           save_freq=\"epoch\")\n",
    "\n",
    "es_cb = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5796a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Started the refinance of home mortgage process...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128951</th>\n",
       "      <td>179770</td>\n",
       "      <td>Barclay closed my Barclay XXXX MasterCard acco...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128952</th>\n",
       "      <td>179771</td>\n",
       "      <td>Our son was taken to XXXX XXXX XXXX XXXX XXXX ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128953</th>\n",
       "      <td>179773</td>\n",
       "      <td>I had an account with XXXX in XX/XX/XXXX this ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128954</th>\n",
       "      <td>179774</td>\n",
       "      <td>I was contacted on XX/XX/XXXX email by XXXX fr...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128955</th>\n",
       "      <td>179775</td>\n",
       "      <td>I had a debit that was included in my chapter ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128956 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               Text Class\n",
       "0                0  I have outdated information on my credit repor...     C\n",
       "1                2  An account on my credit report has a mistaken ...     C\n",
       "2                3  This company refuses to provide me verificatio...     A\n",
       "3                4  This complaint is in regards to Square Two Fin...     A\n",
       "4                5  Started the refinance of home mortgage process...     B\n",
       "...            ...                                                ...   ...\n",
       "128951      179770  Barclay closed my Barclay XXXX MasterCard acco...     D\n",
       "128952      179771  Our son was taken to XXXX XXXX XXXX XXXX XXXX ...     A\n",
       "128953      179773  I had an account with XXXX in XX/XX/XXXX this ...     A\n",
       "128954      179774  I was contacted on XX/XX/XXXX email by XXXX fr...     B\n",
       "128955      179775  I had a debit that was included in my chapter ...     A\n",
       "\n",
       "[128956 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('nlp.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e646bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c09f3c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D'], dtype='<U1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "label = one_hot_encoder.fit_transform(data[\"Class\"].to_numpy().reshape(-1,1))\n",
    "\n",
    "# raw_df[\"label\"] = label\n",
    "class_names = np.array(one_hot_encoder.categories_, dtype=\"str\")[0]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e95ba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103164, 25792, 103164, 25792)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(data.Text.to_numpy(),\n",
    "                                                                            label,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42)\n",
    "\n",
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7edf851",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5662fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(val_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc5ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3224/3224 [==============================] - 19s 6ms/step - loss: 0.3861 - accuracy: 0.8626 - val_loss: 0.3125 - val_accuracy: 0.8932\n",
      "Epoch 2/10\n",
      "3224/3224 [==============================] - 19s 6ms/step - loss: 0.2888 - accuracy: 0.9012 - val_loss: 0.2904 - val_accuracy: 0.9008\n",
      "Epoch 3/10\n",
      "3224/3224 [==============================] - 19s 6ms/step - loss: 0.2639 - accuracy: 0.9097 - val_loss: 0.2869 - val_accuracy: 0.9025\n",
      "Epoch 4/10\n",
      "3224/3224 [==============================] - 26s 8ms/step - loss: 0.2435 - accuracy: 0.9174 - val_loss: 0.2839 - val_accuracy: 0.9036\n",
      "Epoch 5/10\n",
      "3224/3224 [==============================] - 24s 7ms/step - loss: 0.2260 - accuracy: 0.9231 - val_loss: 0.2899 - val_accuracy: 0.9036\n",
      "Epoch 6/10\n",
      "3224/3224 [==============================] - 20s 6ms/step - loss: 0.2096 - accuracy: 0.9295 - val_loss: 0.3001 - val_accuracy: 0.9020\n",
      "Epoch 7/10\n",
      "3224/3224 [==============================] - 21s 6ms/step - loss: 0.1942 - accuracy: 0.9341 - val_loss: 0.2993 - val_accuracy: 0.9022\n",
      "Epoch 8/10\n",
      "3224/3224 [==============================] - 27s 8ms/step - loss: 0.1819 - accuracy: 0.9392 - val_loss: 0.3193 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "3224/3224 [==============================] - 27s 8ms/step - loss: 0.1693 - accuracy: 0.9426 - val_loss: 0.3400 - val_accuracy: 0.8916\n",
      "Epoch 10/10\n",
      "3224/3224 [==============================] - 25s 8ms/step - loss: 0.1588 - accuracy: 0.9465 - val_loss: 0.3372 - val_accuracy: 0.8988\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "# Fit the model\n",
    "model_history = model.fit(training_padded,train_labels,\n",
    "                              validation_data=(testing_padded,val_labels),\n",
    "                              epochs=10,\n",
    "                              callbacks=[create_checkpoint_callback(model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d422da3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_preds = model.predict(testing_padded)\n",
    "model_0_preds=tf.argmax(model_0_preds, axis=1)\n",
    "model_0_preds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68448c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128956, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].to_numpy().reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76701634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2ba4eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25792, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_preds.numpy().reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f343ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_preds = model.predict(testing_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59fa3ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['B'],\n",
       "       ['D'],\n",
       "       ['A'],\n",
       "       ...,\n",
       "       ['A'],\n",
       "       ['A'],\n",
       "       ['A']], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoder.inverse_transform(model_0_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14b1bc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625d445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b227deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eab53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f2b982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data[\"Title\"]\n",
    "label = one_hot_encoder.fit_transform(data[\"Conference\"].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e467044f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2005, 502, 2005, 502)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(sentences.to_numpy(),\n",
    "                                                                            label,\n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=42)\n",
    "\n",
    "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df04f2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a682769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6631"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = \" \".join(train_sentences)\n",
    "vocab = set(vocab.split(\" \"))\n",
    "vocab_len = len(vocab)\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5624105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 1000 # max number of words to have in our vocabulary\n",
    "max_length = 9 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=max_length) # how long should the output sequence of tokens be?\n",
    "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d83b8bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=64, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad1242cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 5s 25ms/step - loss: 1.0712 - accuracy: 0.6180 - val_loss: 0.9876 - val_accuracy: 0.5996\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.3326 - accuracy: 0.8923 - val_loss: 1.1895 - val_accuracy: 0.6594\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1903 - accuracy: 0.9411 - val_loss: 1.2607 - val_accuracy: 0.6355\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1458 - accuracy: 0.9566 - val_loss: 1.4871 - val_accuracy: 0.6474\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1393 - accuracy: 0.9566 - val_loss: 1.5582 - val_accuracy: 0.6295\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1353 - accuracy: 0.9586 - val_loss: 1.6313 - val_accuracy: 0.5936\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.1028 - accuracy: 0.9681 - val_loss: 1.7164 - val_accuracy: 0.6275\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.0882 - accuracy: 0.9756 - val_loss: 1.9622 - val_accuracy: 0.6135\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0811 - accuracy: 0.9761 - val_loss: 1.9717 - val_accuracy: 0.6096\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.0874 - accuracy: 0.9736 - val_loss: 1.9336 - val_accuracy: 0.6414\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"input_layer\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(tf.keras.layers.LSTM(32))(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs, name=\"model_LSTM\")\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "# Fit the model\n",
    "model_history = model.fit(train_sentences,train_labels,\n",
    "                              validation_data=(val_sentences,val_labels),\n",
    "                              epochs=10,\n",
    "                              callbacks=[create_checkpoint_callback(model.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd1719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858c630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a9bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109af802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
